---
title: "Raport 1"
author: "Aleksander Milach"
date: "25 kwietnia 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(bigstep)
library(MASS)

```

## Zadanie 1 

```{r z1prep, cache=T}
X=matrix(rnorm(950000,0,1/sqrt(1000)),1000,950)
Xnew=matrix(rnorm(950000,0,1/sqrt(1000)),1000,950)
Beta=c(rep(16,5),rep(0,945))
eps=rnorm(1000)
Y=X%*%Beta+eps
n=1000

Xnew=matrix(rnorm(950000,0,1/sqrt(1000)),1000,950)
Ynew=Xnew%*%Beta+rnorm(1000)

numerki=c(5,10,20,100,500,950)

zad1=function(k){
    Xs=X[,1:k]
    Xnews=Xnew[,1:k]
    Hs=Xs%*%solve(t(Xs)%*%Xs)%*%t(Xs)
    m=lm(Y~Xs)
    
    estbeta=solve(t(Xs)%*%Xs)%*%t(Xs)%*%Y
    RSS=deviance(m)
    PE=sum((Ynew-Xnews%*%estbeta)^2)
    sig=summary(m)$sigma
    estPE1=RSS+2*1*k #=AICznane
    estPE2=RSS+2*sig^2*k 
    estPE3=0
    for(i in 1:1000)
        estPE3=estPE3+((Y[i]-Xs[i,]%*%estbeta)/(1-Hs[i,i]))^2
    AICnz=RSS+2*RSS/(n-k)*k
    v=c(RSS,PE,estPE1,estPE2,estPE3,AICnz)
    names(v)=c('RSS','PE','estPE1(AICzn)','estPE2','estPE3','AICnz')
  return(v)
}

```

```{r z1a, cache=T}

Z1a=sapply(numerki,zad1)
znane=which.min(Z1a[3,])
nznane=which.min(Z1a[6,])

kable(Z1a,format='markdown',col.names = c('5 zmiennych','10 zmiennych','20 zmiennych',  
                                          '100 zmiennych','500 zmiennych','950 zmiennych'))
```

W obu przypadkach AIC, dla znanego i nieznanego sigma, AIC wybiera model z 5 zmiennymi.

```{r z1duze,fig.align='center', fig.height=3.6}

U=array(0, c(4,6,100))

for(j in 1:100){
  X=matrix(rnorm(950000,0,1/sqrt(1000)),1000,950)
  Y=X%*%Beta+rnorm(1000)
  Xnew=matrix(rnorm(950000,0,1/sqrt(1000)),1000,950)
  Ynew=Xnew%*%Beta+rnorm(1000)
  U[,,j]=sapply(numerki,zad1)[2:5,]
}


boxplot(-(U[1,1,]-U[2,1,]),-(U[1,1,]-U[3,1,]),-(U[1,1,]-U[4,1,]),main='5 pierwszych zmiennych Estymatory-PE')

boxplot(-(U[1,2,]-U[2,2,]),-(U[1,2,]-U[3,2,]),-(U[1,2,]-U[4,2,]),main='10 pierwszych zmiennych Estymatory-PE')

boxplot(-(U[1,3,]-U[2,3,]),-(U[1,3,]-U[3,3,]),-(U[1,3,]-U[4,3,]),main='20 pierwszych zmiennych Estymatory-PE')

boxplot(-(U[1,4,]-U[2,4,]),-(U[1,4,]-U[3,4,]),-(U[1,4,]-U[4,4,]),main='100 pierwszych zmiennych Estymatory-PE')

boxplot(-(U[1,5,]-U[2,5,]),-(U[1,5,]-U[3,5,]),-(U[1,5,]-U[4,5,]),main='500 pierwszych zmiennych Estymatory-PE')

boxplot(-(U[1,6,]-U[2,6,]),-(U[1,6,]-U[3,6,]),-(U[1,6,]-U[4,6,]),main='950 pierwszych zmiennych Estymatory-PE')

```

Nawet gdy bierzemy 100 pierwszych zmiennych wszystkie estymatory błędu predykcji mają średnią zero i rozsądną wariancję.
W przypadku gdy n=500 lub n=950 estymatory związane z RSS zaczynają zaniżać błąd predykcji, jest to przykład na przepasowanie modelu do danych; gdy p zbliża się do n, model dopasowuje się do losowego błędu. 

## Zadanie 2

```{r z2prep, cache=T}

zad2=function(Y2,i)
{
    D=prepare_data(Y2,X[,1:numerki2[i]])
    
    a=as.integer(fast_forward(D,crit=aic)$model)
    Ta=length(intersect(a,1:5))
    Fa=length(a)-Ta
    powa=Ta/5
    FDRa=Fa/(Ta+Fa)
    MSEa=sum((predict(lm(Y~X[,a]))-X%*%Beta)^2)/1000
    
    b=as.integer(fast_forward(D,crit=bic)$model)
    Tb=length(intersect(b,1:5))
    Fb=length(b)-Tb
    powb=Tb/5
    FDRb=Fb/(Tb+Fb)
    MSEb=sum((predict(lm(Y~X[,b]))-X%*%Beta)^2)/1000
    
    m=as.integer(fast_forward(D,crit=mbic)$model)
    Tm=length(intersect(m,1:5))
    Fm=length(m)-Tm
    powm=Tm/5
    FDRm=Fm/(Tm+Fm)
    MSEm=sum((predict(lm(Y~X[,m]))-X%*%Beta)^2)/1000
    
    m2=as.integer(fast_forward(D,crit=mbic2)$model)
    Tm2=length(intersect(m2,1:5))
    Fm2=length(m2)-Tm2
    powm2=Tm2/5
    FDRm2=Fm2/(Tm2+Fm2)
    MSEm2=sum((predict(lm(Y~X[,m2]))-X%*%Beta)^2)/1000
    
    v=c(powa,FDRa,MSEa,powb,FDRb,MSEb,powm,FDRm,MSEm,powm2,FDRm2,MSEm2)
    return(v)
}

numerki2=c(20,100,500,950)
```

# Podpunkt a

```{r z2a, warning=FALSE ,message=FALSE, cache=T}

Y2a=X%*%Beta+rnorm(1000)
zad2a=rbind(zad2(Y2a,1),zad2(Y2a,2),zad2(Y2a,3),zad2(Y2a,4))
colnames(zad2a)=c('Ta','Fa','SEa','Tb','Fb','SEb','Tm','Fm','SEm','Tm2','Fm2','SEm2') 
rownames(zad2a)=c('20 zmiennych','100 zmiennych','500 zmiennych','950 zmiennych')

kable(zad2a,format='markdown')
```


# Podpunkt b 

```{r z2b, message=FALSE, cache=T}

E=array(0,dim=c(100,4,12))

for(j in 1:100)
{
  Y2=X%*%Beta+rnorm(1000)
for(i in 1:4)
{
  E[j,i,]=zad2(Y2,i)
}
}

zad2b=rbind(c(mean(E[,1,1]),mean(E[,1,2]),mean(E[,1,3]),mean(E[,1,4]),mean(E[,1,5]),mean(E[,1,6]),mean(E[,1,7]),
mean(E[,1,8]),mean(E[,1,9]),mean(E[,1,10]),mean(E[,1,11]),mean(E[,1,12])),
c(mean(E[,2,1]),mean(E[,2,2]),mean(E[,2,3]),mean(E[,2,4]),mean(E[,2,5]),mean(E[,2,6]),mean(E[,2,7]),
mean(E[,2,8]),mean(E[,2,9]),mean(E[,2,10]),mean(E[,2,11]),mean(E[,2,12])),
c(mean(E[,3,1]),mean(E[,3,2]),mean(E[,3,3]),mean(E[,3,4]),mean(E[,3,5]),mean(E[,3,6]),mean(E[,3,7]),
mean(E[,3,8]),mean(E[,3,9]),mean(E[,3,10]),mean(E[,3,11]),mean(E[,3,12])),
c(mean(E[,4,1]),mean(E[,4,2]),mean(E[,4,3]),mean(E[,4,4]),mean(E[,4,5]),mean(E[,4,6]),mean(E[,4,7]),
mean(E[,4,8]),mean(E[,4,9]),mean(E[,4,10]),mean(E[,4,11]),mean(E[,4,12])))


colnames(zad2b)=c('Pow. AIC','FDR AIC','MSE AIC','Pow. BIC','FDR BIC','MSE BIC', 
               'Pow. mBIC','FDR mBIC','MSE mBIC','Pow. mBIC2','FDR mBIC2','MSE mBIC2')
rownames(zad2b)=c('20 zmiennych','100 zmiennych','500 zmiennych','950 zmiennych')
kable(t(zad2b),format = 'markdown')
```

Każde z kryteriów znalazło wszystkie zmienne znaczące,jednak w szczególności AIC i BIC dla n=500 i n=950 mamy bardzo dużo fałszywych odkryć. Znacznie mniej fałszywych odkryć wybierało mBIC i mBIC2, dla każdego z czterech modeli.


## Zadanie 3

```{r z3, message=FALSE, cache=T}
Beta3=c(rep(3,50),rep(0,900))
Y3=X%*%Beta3+eps

k3=950
n3=1000
p3=950
m3=lm(Y3~X)

D3=prepare_data(Y3,X)
mbic3coef=fast_forward(D3,crit=mbic)$model
mbic23coef=fast_forward(D3,crit=mbic2)$model
ric3coef=fast_forward(D3,crit=function(loglik,k,p){-2*loglik+2*k*log(p)})$model

mbic3coef
mbic23coef
ric3coef
```

## Zadanie 4

```{r z4prep, message=FALSE, cache=T}

beta4=c(rep(10,30),rep(0,920))
Y4a=X%*%beta4+(rexp(1000)-1)
Y4b=X%*%beta4+rcauchy(1000)

z4=function(Y4a)
{
D4=prepare_data(Y4a,X)

m=as.integer(fast_forward(D4,crit=mbic)$model)
Tm=length(intersect(m,1:30))
Fm=length(m)-Tm

m2=as.integer(fast_forward(D4,crit=mbic2)$model)
Tm2=length(intersect(m2,1:30))
Fm2=length(m2)-Tm2

rY4=rank(Y4a)
D4r=prepare_data(rY4,X)

rm=as.integer(fast_forward(D4r,crit=mbic)$model)
Trm=length(intersect(rm,1:30))
Frm=length(rm)-Trm

rm2=as.integer(fast_forward(D4r,crit=mbic2)$model)
Trm2=length(intersect(rm2,1:30))
Frm2=length(rm2)-Trm2

v=c(Tm,Fm,Tm2,Fm2,Trm,Frm,Trm2,Frm2)
names(v)=c('Tm','Fm','Tm2','Fm2','Trm','Frm','Trm2','Frm2')
return(v)
}

zad4b=function(rm2){
z4bm=lm(Y4a~X[,rm2])
z4bmH=rlm(X[,rm2],Y4a,psi=psi.huber)
z4bmB=rlm(X[,rm2],Y4a,psi=psi.bisquare)
z4bMSEOLS=sum((predict(z4bm)-X%*%Beta)^2)/1000
z4bMSEHub=sum((X[,rm2]%*%summary(z4bmH)$coefficients[,1]-X%*%Beta)^2)/1000
z4bMSEBsq=sum((X[,rm2]%*%summary(z4bmB)$coefficients[,1]-X%*%Beta)^2)/1000
v=c(z4bMSEOLS,z4bMSEHub,z4bMSEBsq)
return(v)
}

```

# Podpunkt a

```{r z4a, message=FALSE, cache=T}
T=cbind(z4(Y4a),
z4(Y4b))
colnames(T)=c('Shifted exp.','Cauchy')
kable(t(T),format = 'markdown')
```

W przypadku rozkładu wykładniczego, każde z kryteriów zachowuje się podobnie, znajduje znaczną większość zmiennych istotnychi mało lub żadnych fałszywych odkryć.

Dla rozkładu Cauchy'ego kryteria mBIC i mBIC2 nie znajdują żadnych zmiennych istotnych, błąd o rozkładzie Cauchy'ego jest 'za trudny' dla zwykłych kryteriów. Kiedy zastosujemy podejście rangowe kryteria znajdują część (około 1/4) zmiennych istotnych, bez fałszywych odkryć.

# Podpunkt b

```{r z4b, message=FALSE}

rY4exp=rank(Y4a)
D4rexp=prepare_data(rY4exp,X)
rm2exp=as.integer(fast_forward(D4rexp,crit=mbic2)$model)

rY4cy=rank(Y4b)
D4rcy=prepare_data(rY4cy,X)
rm2cy=as.integer(fast_forward(D4rcy,crit=mbic2)$model)

Y=cbind(zad4b(rm2exp),zad4b(rm2cy))
colnames(Y)=c('Shifted exp.','Cauchy')
rownames(Y)=c('LM',"Huber",'Bsquare')
kable(t(Y), format = 'markdown')
```

Powyżej wymieniłem wartości MSE dla każdego z eksperymentów.

# Podpunkt c

```{r z4c,message=FALSE}

Ua=matrix(0,8,100)
Ub=matrix(0,8,100)
for(i in 1:100)
{
  Y4a=X%*%beta4+(rexp(1000)-1)
  Y4b=X%*%beta4+rcauchy(1000)
  Ua[,1]=z4(Y4a)
  Ub[,1]=z4(Y4b)
}

z4a3=c(mean(Ua[1,])/30*100,
mean(Ua[2,])/950*100,
mean(Ua[3,])/30*100,
mean(Ua[4,])/950*100,
mean(Ua[5,])/30*100,
mean(Ua[6,])/950*100,
mean(Ua[7,])/30*100,
mean(Ua[8,])/950*100)
names(z4a3)=c("Pow. mBIC",'FDR mBIC','Pow. mBIC2','FDR mBIC2','Pow. rBIC','FDR rBIC','Pow. rBIC2','FDR rBIC2')

z4b3=c(mean(Ub[1,])/30*100,
mean(Ub[2,])/950*100,
mean(Ub[3,])/30*100,
mean(Ub[4,])/950*100,
mean(Ub[5,])/30*100,
mean(Ub[6,])/950*100,
mean(Ub[7,])/30*100,
mean(Ub[8,])/950*100)
names(z4b3)=c("Pow. mBIC",'FDR mBIC','Pow. mBIC2','FDR mBIC2','Pow. rBIC','FDR rBIC','Pow. rBIC2','FDR rBIC2')

I=cbind(z4a3,z4b3)
colnames(I) = c('Exp.','Cauchy')
kable(t(I),format='markdown')
```

Dla błędu o rozkładzie wykładniczym mamy bardzo pożądane własności, moc powyżej 0.9 i sporadyczne fałszywe odkrycia.
Dla błędu o rozkładzie Cauchy'ego kryteria nierangowe nie znajdują żadnych zmiennych, zaś rangowe znajdują niektóre zmienne istotne, ale wciąż bardzo mały ich ułamek.